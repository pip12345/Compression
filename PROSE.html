<!DOCTYPE html>
<html>
<head>
<title>PROSE.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="compression-huffman-coding-and-the-lzw-algorithm">Compression: Huffman coding and the LZW algorithm</h1>
<h2 id="by-floris-de-bruin-438652---dec-2023---course-advanced-programming-concepts">By: Floris de Bruin (438652) - Dec. 2023 - Course: Advanced Programming Concepts</h2>
<p><strong>Overview:</strong></p>
<pre class="hljs"><code><div>Content:
+ 1. Introduction
+ 2. Design overview
+ 3. Huffman coding
    - 3.1 Introduction
    - 3.2 Theory behind the algorithm
    - 3.3 Implementation in the program
        - 3.3.1 Program overview
        - 3.3.2 Frequency table: counting letters
        - 3.3.3 Building the tree
        - 3.3.4 Decoding table: tree traversal
        - 3.3.5 Encoding
        - 3.3.6 Decoding
+ 4. The LZW (Lempel–Ziv–Welch) algorithm
    - 4.1 Introduction
    - 4.2 Theory behind the algorithm
    - 4.3 Implementation in the program
        - 4.3.1 Program overview
        - 4.3.2 Encoding
        - 4.3.3 Decoding
+ 5. File handling
+ 6. Benchmarking
+ 7. Reflection
+ 8. References
</div></code></pre>
<h2 id="1-introduction">1. Introduction</h2>
<p>The purpose of the assignment is implementing the compression and decompression of files using the
Huffman coding algorithm and the LZW (Lempel–Ziv–Welch) algorithm.
The learning objectives are to implement both these algorithms, and a simple program to encode and decode
text files in order to test these algorithms.</p>
<p>The core subject of this assignment is compression. Compression is the process of reducing the size of a file by
encoding information in a more efficient way. It removes redundant or unnecessary data, allowing the file to take up
less storage space. These savings are essential for systems that consist out of millions of files, or for applications
where storage space may be limited such as for data transmission.
Compression is at its core about finding patterns and redundancy within data and reducing these
redundancies. Both to-be-covered algorithms are lossless, which means that no information may be lost after a cycle of
compression and decompression.</p>
<h2 id="2-design-overview">2. Design Overview</h2>
<p>Below is an image of the total program developed for this assignment. The program contains:</p>
<ul>
<li>Two algorithms (LZW and Huffman) for compressing and decompressing files</li>
<li>A file handler to manage opening, reading and writing binary to/from files</li>
<li>An encompassing compression handling class that incorporates all the above elements into simple to use functions.</li>
</ul>
<div style="display: flex">
<img style="margin: auto" src="docs/img/Overview.png" alt="UML overview of the program" width="1300"/>
</div>
<div style="text-align: center;">
Figure 1: UML Overview of the program (public methods only)
</div>
<h2 id="3-huffman-coding">3. Huffman coding</h2>
<h3 id="31-introduction">3.1 Introduction</h3>
<p>Huffman coding is an algorithm that efficiently assigns variable-length codes to different characters in a text file,
where more frequent characters receive shorter codes, reducing overall space while retaining the original information.</p>
<p>The downside of this algorithm is that the data used to encode the text has to be included with the encoded text in order
to be able to decode it. This is a permanent overhead that leads to worse compression ratios for smaller files.</p>
<h3 id="32-theory-behind-the-algorithm">3.2 Theory behind the algorithm</h3>
<p>Compressing a file using Huffman coding works as follows:</p>
<ol>
<li>
<p><em>Building the frequency table</em>: The algorithm starts by analyzing the text to determine the frequency of
each character. Each character will get assigned a unique code depending on their frequency.
More frequent characters will be assigned a shorter code, and less frequent ones will have longer codes.</p>
</li>
<li>
<p><em>Building the Huffman tree</em>: After building the frequency table, a tree is built using an
algorithm that walks through the frequency table and merges the two least frequent characters at each step until all characters are merged and form a
single tree.</p>
</li>
<li>
<p><em>Building the coding table</em>: Once the Huffman tree is built, each character in the tree (leaf nodes) receives a unique binary code.
These codes are derived by traversing the tree from the root to each character, assigning '0' for the left branch and '1'
for the right branch.</p>
</li>
<li>
<p><em>Encoding the text</em>: With the codes assigned, the original data is then encoded by replacing each character with its corresponding
Huffman code. This compressed representation is smaller than the original data, especially when frequent characters are
represented by shorter codes. The resulting encoded text has either the coding table, huffman tree or frequency table included in order to decode the text.
In this implementation the frequency table was chosen.</p>
</li>
</ol>
<div style="display: flex">
<img style="margin: auto" src="docs/img/huff_encoding.png" alt="Steps for Huffman encoding" width="600"/>
</div>
<div style="text-align: center;">
Figure 2: Steps for Huffman encoding and saving
</div>&nbsp
<p>Decoding is simply the same process in reverse if the frequency table is included, or in the case the coding table is included
the text can immediately be decoded.</p>
<ul>
<li>
<p>Decoding with the frequency table: Using the included frequency table, the Huffman tree is built. The tree is then traversed
according to the &quot;instructions&quot; in the encoded data. The encoded data essentially forms a route from the root of the tree to a leaf node.
Each 0 is a left turn and each 1 is a right turn. The letter corresponding to the leaf node at the end destination is the decoded letter.</p>
</li>
<li>
<p>Decoding with the coding table: This is a direct approach that doesn't require rebuilding the tree, at the cost of
extra overhead that has to be saved with the encoded data. The encoded data can simply be read out and compared with
the codes in the coding table, and decoded.</p>
</li>
</ul>
<div style="display: flex">
<img style="margin: auto" src="docs/img/huff_decoding.png" alt="Steps for Huffman decoding" width="800"/>
</div>
<div style="text-align: center;">
Figure 3: Steps for Huffman decoding
</div>&nbsp
<p>In order to get consistent encoding and decoding results, some extra rules may be put in place that aren't necessarily
part of the Huffman algorithm, such as ordering equal weighted leaf nodes alphabetically when constructing the tree.
These rules are implementation dependent, therefore the exact implementation must be known in order to decode a Huffman
encoded text.</p>
<h4 id="example-tree">Example tree:</h4>
<p>Below is an example tree for the word &quot;programming&quot;. The blue nodes are root nodes that include the sum
of the total frequencies of all its child nodes. The purple leaf nodes are the characters with their frequency.</p>
<p>When traversing the tree, a left branch is a '0' and a right branch is a '1'.</p>
<p>The code for each character is the path traversed from the top tree root to a leaf.</p>
<div style="display: flex">
<img style="margin: auto" src="docs/img/Alphabetically ordered single frequencies.png" alt="Generated tree for the word Programming" width="1300"/>
</div>
<div style="text-align: center;">
Figure 4: Generated tree and code table for the word Programming
</div>
<h3 id="33-implementation-in-the-program">3.3 Implementation in the program</h3>
<h4 id="331-program-overview">3.3.1 Program overview</h4>
<p>The Huffman coding part of the program consists of the following classes:</p>
<ul>
<li>
<p><em>Huffman_coder</em>: Generates the frequency table from a passed string, and encodes/decodes this string using the coding table generated by Tree.</p>
</li>
<li>
<p><em>Tree</em>: Builds a tree out of a passed frequency table, then returns the coding table generated from traversing the tree using a recursive pathing function.</p>
</li>
</ul>
<p>The activity diagram below shows the interaction between both classes during encoding and decoding.</p>
<div style="display: flex">
<img style="margin: auto" src="docs/img/Activity diagram Huffman.png" alt="Activity diagram of Huffman code" width="500"/>
</div>
<div style="text-align: center;">
Figure 5: Activity diagram of Huffman_coder and Tree
</div>
<h4 id="332-frequency-table-counting-letters">3.3.2 Frequency table: counting letters</h4>
<p>The tree will be built out of nodes. Each node needs to be able to contain both the frequency and a character. The node also contains
pointers to its left or right children (if they exist). This allows us to construct a tree out of them.</p>
<p>If it's a root node that only contains a frequency of its children, the character will be set to the reserved symbol '~'.</p>
<pre class="hljs"><code><div>    <span class="hljs-comment">// Min heap node in the huffman tree</span>
    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> {</span>
        <span class="hljs-keyword">int</span> freq;
        <span class="hljs-keyword">char</span> data;
        Node *left{<span class="hljs-literal">nullptr</span>};
        Node *right{<span class="hljs-literal">nullptr</span>};

        Node(<span class="hljs-keyword">char</span> data, <span class="hljs-keyword">int</span> freq) {
            <span class="hljs-keyword">this</span>-&gt;freq = freq;
            <span class="hljs-keyword">this</span>-&gt;data = data;
        }
    };
</div></code></pre>
<p>Since nodes allow us to save characters and their frequency, and have all the necessary infrastructure to build a tree from later,
they're also a good medium to build the frequency table with. To be able to build this frequency table, we need to be able to
convert a string of text to nodes. The following function delivers that.</p>
<p>In short it does the following:</p>
<ol>
<li>Copy the string into a map to get each character and its frequency</li>
<li>Copy the map into a vector of &lt;char, int&gt; pairs, to allow sorting it by frequency</li>
<li>Convert the by-frequency sorted vector of pairs into a vector of nodes</li>
<li>Return above mentioned vector of nodes</li>
</ol>
<pre class="hljs"><code><div>  <span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Node&gt; <span class="hljs-title">Huffman_coder::string_to_nodes</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> &amp;text_str)</span> </span>{
  <span class="hljs-comment">/// Count the frequency of each character, output map is sorted alphabetically first</span>
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">char</span>, <span class="hljs-keyword">int</span>&gt; freq_map; <span class="hljs-comment">// Holds a map of each character and its frequency, sorted alphabetically</span>
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">std</span>::pair&lt;<span class="hljs-keyword">char</span>, <span class="hljs-keyword">int</span>&gt;&gt; freq_sorted{}; <span class="hljs-comment">// Sorted by-frequency vector copy of the map</span>
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Node&gt; nodes{}; <span class="hljs-comment">// Vector of nodes (frequency table) that gets returned</span>

        <span class="hljs-comment">// Traverse the string</span>
        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i{<span class="hljs-number">0</span>}; text_str[i]; i++) {
            <span class="hljs-comment">// If the current character hasn't been found before, set frequency to 1</span>
            <span class="hljs-keyword">if</span> (freq_map.<span class="hljs-built_in">find</span>(text_str[i]) == freq_map.<span class="hljs-built_in">end</span>()) {
                freq_map.insert(<span class="hljs-built_in">std</span>::make_pair(text_str[i], <span class="hljs-number">1</span>));
            } <span class="hljs-keyword">else</span> {
                <span class="hljs-comment">// If the character already exists in the map, increase the frequency</span>
                freq_map[text_str[i]]++;
            }
        }
        
    <span class="hljs-comment">/// Now re-sort by frequency</span>

        <span class="hljs-comment">// Copy map into vector</span>
        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> &amp;it: freq_map) {
            freq_sorted.push_back(it);
        }

        <span class="hljs-comment">// Sort by frequency</span>
        <span class="hljs-built_in">std</span>::sort(freq_sorted.<span class="hljs-built_in">begin</span>(), freq_sorted.<span class="hljs-built_in">end</span>(), cmp_map_sort);
        
    <span class="hljs-comment">/// Convert sorted vector to nodes and add them to nodes vector</span>
        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> &amp;it: freq_sorted) {
            <span class="hljs-function">Node <span class="hljs-title">temp</span><span class="hljs-params">(it.first, it.second)</span></span>;
            nodes.push_back(temp);
        }

        <span class="hljs-keyword">return</span> nodes;
  }
</div></code></pre>
<h4 id="333-building-the-tree">3.3.3 Building the tree</h4>
<p>Now we have the frequency table, we can build a tree from it. We do this with a min-heap.</p>
<p>Initialized in class:</p>
<pre class="hljs"><code><div><span class="hljs-comment">// Min priority queue (min heap) used for building and storing the Huffman tree</span>
        <span class="hljs-built_in">std</span>::priority_queue&lt;Node *, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Node *&gt;, Node_compare&gt; min_heap{};
</div></code></pre>
<p>In case the min-heap still has contents from a previously generated tree, it is cleared first. After that the contents of the frequency table are pushed into the min-heap.</p>
<pre class="hljs"><code><div>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Tree::add_freq_table</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Node&gt; &amp;n)</span> </span>{
        <span class="hljs-comment">// Wipe current contents of min heap (tree)</span>
        clear_min_heap();

        <span class="hljs-comment">// Add new freq_table to min_heap</span>
        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> i: n) {
            min_heap.push(<span class="hljs-keyword">new</span> Node(i.data, i.freq));
        }
        build_tree();
    }
</div></code></pre>
<p>We can now construct a tree from the contents of the min-heap. We do this by constructing it inside this same heap. Because
the nodes in the std::vector of nodes (the frequency table) were already sorted by frequency, we can easily build a Huffman tree out of them.</p>
<p>We do this the following way for as long as the min-heap has unconnected nodes:</p>
<ol>
<li>Extract the 2 lowest frequency nodes from the heap</li>
<li>Make a new root node with its frequency being the sum of these 2 extracted nodes (set to reserved character '~')</li>
<li>Connect the 2 lowest frequency nodes to this new root node,</li>
<li>Push this new root node with the 2 lowest frequency nodes connected back into the min heap.</li>
</ol>
<p>By repeating this we will slowly build a tree from the nodes in the min-heap until everything is connected.</p>
<pre class="hljs"><code><div>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Tree::build_tree</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-comment">// Iterate while heap has loose nodes</span>
        <span class="hljs-keyword">while</span> (min_heap.<span class="hljs-built_in">size</span>() &gt; <span class="hljs-number">1</span>) {
            <span class="hljs-comment">// Extract the 2 lowest freq items from heap</span>
            left = min_heap.top();
            min_heap.pop();

            right = min_heap.top();
            min_heap.pop();

            <span class="hljs-comment">// Add a new root node to these two nodes with the frequency being the sum of the frequency of both left and right children</span>
            <span class="hljs-comment">// '~' character reserved for indicating the root node</span>
            root = <span class="hljs-keyword">new</span> Node(<span class="hljs-string">'~'</span>, left-&gt;freq + right-&gt;freq);
            root-&gt;left = left;
            root-&gt;right = right;

            <span class="hljs-comment">// Push new tree part back into the min heap</span>
            min_heap.push(root);
        }
    }
</div></code></pre>
<h4 id="334-decoding-table-tree-traversal">3.3.4 Decoding table: tree traversal</h4>
<p>Now the tree is built, we need to be able to find the code for each character in the tree. As explained before, the code
for each character is the path traversed from the top tree root to a leaf. For this we use a recursive pathing function
that will path through the tree. The function keeps passing a string to itself where it will add either a &quot;0&quot; or &quot;1&quot; to depending on whether
it has taken a left or right turn at each node.</p>
<pre class="hljs"><code><div>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Tree::coding_table_from_node</span><span class="hljs-params">(Node *n, <span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&amp; code_recursive, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">char</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&gt; &amp;coding_table)</span> </span>{
        <span class="hljs-comment">// If null, we've reached the end, break from recursion</span>
        <span class="hljs-keyword">if</span> (n == <span class="hljs-literal">nullptr</span>) {
            <span class="hljs-keyword">return</span>;
        }

        <span class="hljs-comment">// Only output if it's not a root node</span>
        <span class="hljs-keyword">if</span> (n-&gt;data != <span class="hljs-string">'~'</span>) {
            coding_table.insert(<span class="hljs-built_in">std</span>::make_pair(n-&gt;data, code_recursive));
        }

        coding_table_from_node(n-&gt;left, code_recursive + <span class="hljs-string">"0"</span>, coding_table); <span class="hljs-comment">// Left child, add a 0 to the code</span>
        coding_table_from_node(n-&gt;right, code_recursive + <span class="hljs-string">"1"</span>, coding_table); <span class="hljs-comment">// Right child, add 1 to the code</span>
    }
</div></code></pre>
<p>In order to decode the tree, we need to pass the recursive function the start (root), an empty string it can use
to build the code in, and a std::map it can use to build the coding table.</p>
<pre class="hljs"><code><div>    <span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">char</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&gt; <span class="hljs-title">Tree::return_coding_table</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">char</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&gt; temp_coding_table{};
        coding_table_from_node(root, <span class="hljs-string">""</span>, temp_coding_table);

        <span class="hljs-keyword">return</span> temp_coding_table;
    }
</div></code></pre>
<h4 id="335-encoding">3.3.5 Encoding</h4>
<p>Now we have the coding table for the original string, we can encode it. This is done by looking up the code that
belongs to each character in the original string with the coding table.</p>
<pre class="hljs"><code><div>    <span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> <span class="hljs-title">Huffman_coder::code_with_coding_table</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> &amp;text_str,
                                                      <span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">char</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&gt; &amp;coding_table)</span> </span>{

        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> coded{};

        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> i: text_str) {
            coded.append(coding_table.<span class="hljs-built_in">find</span>(i)-&gt;second);
        }

        <span class="hljs-keyword">return</span> coded;
    }
</div></code></pre>
<p>We can now write the binary representing string (a string where each bit is a character '1' or '0') and the frequency table of the original text to a file. For this a function
is used to be able to write the binary of the coded string to file. The exact way this is done is a detail that's not
crucial for understanding the concept of this algorithm, but was a large challenge in implementation regardless.</p>
<h4 id="336-decoding">3.3.6 Decoding</h4>
<p>For decoding we get the frequency table that was included with the encoded data to do the above steps again to generate the coding table.
It's important to mention that since Huffman coding works with arbitrary length, it's possible the last code written
to a file is shorter than a byte. Therefore, the information about the total length of the original string is lost during
encoding. Luckily we write the total length of the original file inside the frequency table that's included with the
encoded data. When opening a file and converting it back to a binary representing string, this saved length is used
to get back exactly the data that was encoded, without extra trailing zeroes from trying to fit it into a byte.</p>
<p>Once we have the encoded data back, we decode by reading the encoded data bit by bit and checking if the current sequence
of bits is a code that exists in the coding table. We repeat this until we have read all encoded data.</p>
<pre class="hljs"><code><div>    <span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> <span class="hljs-title">Huffman_coder::decode_with_coding_table</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> encoded_text_str,
                                                        <span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">char</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&gt; &amp;coding_table)</span> </span>{

        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> read_buffer{};
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> output_string{};
        <span class="hljs-keyword">auto</span> reversed_table = reverse_map(coding_table);

        <span class="hljs-comment">// We will copy an element from encoded_text_str to read_buffer, then remove it from the encoded_text_str</span>
        <span class="hljs-comment">// Read_buffer will be checked to the coding table:</span>
        <span class="hljs-comment">// If the contents of read_buffer are equal to the code of a character from the coding table,</span>
        <span class="hljs-comment">// then the corrresponding character will be added to the output string and read_buffer will be wiped</span>
        <span class="hljs-comment">// This will continue until encoded_text_str is empty;</span>

        <span class="hljs-comment">// add a code number to the buffer until it is something that exists inside the coding table</span>
        <span class="hljs-keyword">while</span> (!encoded_text_str.empty()) {
            read_buffer.push_back(encoded_text_str.front()); <span class="hljs-comment">// Add front element of encoded text to read buffer</span>

            encoded_text_str.erase(encoded_text_str.<span class="hljs-built_in">begin</span>()); <span class="hljs-comment">// delete front element from encoded text</span>

            <span class="hljs-comment">// Check if the code contents of read buffer correspond to a character in the map</span>
            <span class="hljs-comment">// map.find() returns the end iterator if nothing is found</span>

            <span class="hljs-comment">// If the value exists</span>
            <span class="hljs-keyword">if</span> (reversed_table.<span class="hljs-built_in">find</span>(read_buffer) != reversed_table.<span class="hljs-built_in">end</span>()) {

                <span class="hljs-comment">// add the corresponding character of the code to the output string</span>
                output_string.push_back(reversed_table.<span class="hljs-built_in">find</span>(read_buffer)-&gt;second);

                <span class="hljs-comment">// Wipe the read_buffer</span>
                read_buffer.<span class="hljs-built_in">clear</span>();
            }
        }

        <span class="hljs-keyword">if</span> (!read_buffer.empty()) {
            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">cerr</span>
                    &lt;&lt; <span class="hljs-string">"read_buffer wasn't empty, therefore a character was in the decoding string that wasn't encoded in the coding table!"</span>;
        }

        <span class="hljs-keyword">return</span> output_string;
    }
</div></code></pre>
<h2 id="4-the-lzw-lempel%E2%80%93ziv%E2%80%93welch-algorithm">4. The LZW (Lempel–Ziv–Welch) Algorithm</h2>
<h3 id="41-introduction">4.1 Introduction</h3>
<p>The LZW (Lempel-Ziv-Welch) algorithm is a dictionary-based compression algorithm. It works by replacing sequences of data with codes,
building a dictionary of these sequences as it walks through it. When it encounters a repeated sequence saved previously in the dictionary,
it outputs the corresponding code. This method effectively reduces the size of the data by storing repeated patterns more efficiently.</p>
<p>What is meant by a &quot;sequence of data&quot; can be anything from words such as &quot;the&quot; which can appear hundreds of times
in a large text, to simply a small combination of letters such as &quot;th&quot;, &quot;ck&quot; and &quot;nk&quot;, which usually appear in many different words.
By encoding these with a single code that is less bits than the individual characters on their own, compression is attained.
This also means that the more unique sequences there are in an encoded text, the worse the compression will be, since it relies on repetition of sequences.
In the worst case, there is no compression at all.</p>
<p>The largest advantage of LZW over Huffman is that the encoded data doesn't need any added frequency table or &quot;code book&quot;
to decode it. The dictionary used to encode a file with LZW can be rebuilt while decoding it.
This reduces the overhead significantly by eliminating the need to store extra data with the encoded text. It is also much faster
since no complex tree datastructures have to be generated.</p>
<h3 id="42-theory-behind-the-algorithm">4.2 Theory behind the algorithm</h3>
<p>Compressing a file with LZW works as follows:</p>
<ol>
<li>
<p><em>Initialization</em>: The algorithm initializes a dictionary containing all 256 default ASCII characters. Each symbol takes a unique code which is equal to their position in the dictionary.</p>
</li>
<li>
<p><em>Building the dictionary</em>: The algorithm scans the input data and looks for sequences of characters that repeat. When a sequence is found for the first time, it adds it to the dictionary and assigns it the next available position/code in the dictionary. It keeps doing this for subsequent sequences, updating the dictionary and generating new codes as needed.</p>
</li>
<li>
<p><em>Encoding</em>: As the dictionary is being built, the resulting code for each sequence of characters is output to a file. This is the encoded file.</p>
</li>
<li>
<p><em>Decoding</em>: To decode the compressed data, the receiver uses the same default initialized dictionary to decode the first (and therefore known) characters of the file.
Since each subsequent sequence of characters is created from this known initial set, the entire dictionary can be rebuilt.</p>
</li>
</ol>
<p>LZW's efficiency relies on its ability to create new codes for longer sequences of characters encountered,  reducing the overall size of the data.
Both encoder and decoder must use the same initial dictionary and follow the same rules for encoding/decoding to ensure the dictionary is constructed the same way each time.</p>
<p>Since the code for the encoded data takes the value of the position in the dictionary, the size of the dictionary determines
the level of compression possible. The dictionary is usually between 9 - 16 bits. This is also the number of bits
each &quot;code&quot; takes up in the compressed data.</p>
<p>This means that a larger dictionary allows more unique sequences of characters to be saved, therefore allowing more compression. However, for smaller files with very litle
repeating sequences of characters, using a large dictionary size will hurt the total attainable compression ratio.</p>
<h3 id="43-implementation-in-the-program">4.3 Implementation in the program</h3>
<h4 id="431-program-overview">4.3.1 Program overview</h4>
<p>The program is a quite standard implementation of the LZW algorithm. A notable limitation is that it works with
a non-dynamic dictionary. This means the size of the dictionary can't dynamically be adjusted as it grows.
The size of the dictionary is set by LZW_CODED_MSG_BITS in lzw.h.
This limitation is due to the way conversion to binary is set up. This results in worse compression for smaller files
when LZW_CODED_MSG_BITS is set very high, or worse compression for bigger files when the number of bits is set too low.
An extra added to my implementation is that when the dictionary is full, the algorithm will continue encoding but only by
looking up the entries in the dictionary.</p>
<p>The basic steps of the LZW algorithm are as follows:</p>
<p><strong>Encoding:</strong></p>
<ol>
<li>First we initialize the dictionary with the default 0..255 ascii characters.</li>
<li>Find the longest entry in the dictionary that matches the current input.</li>
<li>Output the index of the longest entry and remove it from the input.</li>
<li>Add (longest entry + the next value) as a key in the next available spot in the dictionary</li>
<li>Repeat 2 to 4 until everything is encoded</li>
</ol>
<p><strong>Decoding:</strong></p>
<ol>
<li>First we initialize the dictionary with the default 0..255 ascii characters.</li>
<li>Read the next value and check if it is encoded in the dictionary.
<ol>
<li>If it is not:
<ol>
<li>Add the previous outputted entry to the current input</li>
<li>Add the above to the dictionary and output it</li>
</ol>
</li>
<li>If it is:
<ol>
<li>Output the matching entry in the dictionary</li>
<li>Add the previous outputted entry to the current output, and add this to the dictionary.</li>
</ol>
</li>
</ol>
</li>
<li>Repeat 2 until everything is decoded</li>
</ol>
<h4 id="432-encoding">4.3.2 Encoding</h4>
<p>The implementation follows the above steps (mostly). Some extra checks are in place for example for checking if the dictionary is full.</p>
<pre class="hljs"><code><div>    <span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> <span class="hljs-title">LZW_coder::encode</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> &amp;text_str)</span> </span>{
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>, <span class="hljs-keyword">int</span>&gt; dict{};
        <span class="hljs-keyword">int</span> dict_size = <span class="hljs-number">256</span>;
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> coded_msg{};
        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> first_input{}; <span class="hljs-comment">// String because we need to be able to append characters: 't' + 'h' = "th"</span>
        <span class="hljs-keyword">bool</span> overflow_flag{<span class="hljs-literal">false</span>};

        <span class="hljs-comment">// Build default dictionary</span>
        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i{<span class="hljs-number">0</span>}; i &lt; dict_size; i++) {
            dict[<span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>{(<span class="hljs-keyword">char</span>) i}] = i;
        }

        <span class="hljs-comment">// Encode the text_str</span>
        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i{<span class="hljs-number">0</span>}; i &lt; text_str.length(); i++) {
            <span class="hljs-keyword">char</span> next_input = text_str[i];

            <span class="hljs-comment">// If first_input + next_input is in the dictionary</span>
            <span class="hljs-keyword">if</span> (dict.count(first_input + next_input)) {
                first_input += next_input;
            } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (dict_size &lt;= <span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>, LZW_CODED_MSG_BITS)) {
                <span class="hljs-comment">// If dictionary isn't full and first_input + next_input is not in the dictionary</span>
                
                <span class="hljs-comment">// Output code</span>
                coded_msg.append(int_to_binary_str(dict[first_input]));

                <span class="hljs-comment">// Add first_input + next_input to the dictionary by setting new fake "ascii" value</span>
                dict[first_input + next_input] = dict_size++;
                first_input = next_input;
            } <span class="hljs-keyword">else</span> {
                <span class="hljs-comment">// If the dictionary is full, stop filling it and encode the rest of the file using the current dictionary</span>
                coded_msg.append(int_to_binary_str(dict[first_input]));
                first_input = next_input;
                <span class="hljs-keyword">if</span> (!overflow_flag) {
                    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">cerr</span> &lt;&lt; <span class="hljs-string">"\nDictionary Overflow, increase LZW_CODED_MSG_BITS!"</span>;
                    overflow_flag = <span class="hljs-literal">true</span>;
                }
            }
        }

            <span class="hljs-comment">// Print the last character</span>
            <span class="hljs-keyword">if</span> (!first_input.empty()) {
                coded_msg.append(int_to_binary_str(dict[first_input]));
            }

            <span class="hljs-keyword">return</span> coded_msg;
        }
</div></code></pre>
<h4 id="433-decoding">4.3.3 Decoding</h4>
<p>This implementation is also mostly identical to the theoretical implementation.</p>
<pre class="hljs"><code><div>        <span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> <span class="hljs-title">LZW_coder::decode</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> &amp;encoded_text_str)</span> </span>{
            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&gt; dict{};
            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> first_input{};
            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> decoded_msg{};
            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> temp{};

            <span class="hljs-keyword">int</span> dict_size = <span class="hljs-number">256</span>;

            <span class="hljs-comment">// Convert binary string to lzw index where each int is the char value of the dictionary</span>
            <span class="hljs-keyword">auto</span> lzw_indexes = binary_string_to_lzw_indexes(encoded_text_str);

            <span class="hljs-comment">// Build default dictionary</span>
            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i{<span class="hljs-number">0</span>}; i &lt; dict_size; i++) {
                dict[i] = (<span class="hljs-keyword">char</span>) i;
            }

            <span class="hljs-comment">// Set initial conditions (first character is always known)</span>
            first_input = dict[lzw_indexes[<span class="hljs-number">0</span>]];
            decoded_msg = dict[lzw_indexes[<span class="hljs-number">0</span>]];

            <span class="hljs-comment">// Continue on and decode from the 2nd</span>
            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i{<span class="hljs-number">1</span>}; i &lt; lzw_indexes.<span class="hljs-built_in">size</span>(); i++) {
                <span class="hljs-keyword">int</span> next_input = lzw_indexes[i];

                <span class="hljs-keyword">if</span> (dict.count(next_input)) {
                    temp = dict[next_input];
                } <span class="hljs-keyword">else</span> {
                    temp = first_input + first_input[<span class="hljs-number">0</span>];
                }

                decoded_msg += temp;
                dict[dict_size++] = first_input + temp[<span class="hljs-number">0</span>];
                first_input = temp;
            }

            <span class="hljs-keyword">return</span> decoded_msg;
        }
</div></code></pre>
<h2 id="5-file-handling">5. File handling</h2>
<p>File handling is managed by the File_handler class. This class has functions to both read and write characters
and individual bits to files. The individual bits are written using binary representing strings.
These are strings with simply characters of '0' and '1' appended to them, which can later be written as actual bits to a file.</p>
<p>The full code of this class is not necessarily interesting for the purpose of this document, especially since it's too long already.
However, the concept of binary representing strings is important for understanding the full code.</p>
<p>Some interesting parts of the file handling were writing and reading the Huffman encoded data to bits. Since it's
arbitrary length and usually did not fit in a single byte. The total Huffman coded data was cut into pieces of 8 bits and written
as a byte to the file. For the last sequence of bits that did not fit in a byte, the rest of the bits in the byte were set to zero.</p>
<p>In order to be able to read the file again and retrieve the Huffman encoded data, the total length of the original encoded
data was written in the frequency table under the reserved '~' character. Using this total count, the last extra trailing zeroes in the last byte could be removed.</p>
<h3 id="an-interesting-issue">An interesting issue</h3>
<p>Originally when reading files I used <code>std::ifstream()</code> in its default reading mode. This made it read all bytes in the
file as characters. However, sometimes encoded files would randomly stop being read by the filestream. The most fascinating thing
is that this would only happen on <strong>Windows</strong>, when running the code on Linux everything worked fine.</p>
<p>Painstakingly debugging a sample text where this issue would occur, I traced it down to end of file (EOF) being triggered
in the filestream when a specific byte was read.</p>
<p>The culprit was 0x1A.</p>
<p>After googling it turns out this byte is interpreted by Windows as a CTRL-Z character, which triggers EOF when read. Thanks Windows.</p>
<p>This issue was fixed by running <code>std::ifstream</code> in its <code>std::ios::binary</code> mode which disables any character interpretation and
conversions.</p>
<div style="display: flex">
<img style="margin: auto" src="docs/img/EOL_compact.png" alt="EOF being triggered" width="900"/>
</div>
<div style="text-align: center;">
Figure 6: EOF being triggered by 0x1A
</div>
<h2 id="6-benchmarking">6. Benchmarking</h2>
<p>To test the compression ratios of the algorithms, a couple of different text files and books were compressed with
both LZW and Huffman. The source, compressed and decompressed files can be found in test_txt.</p>
<p>Below are the benchmark results:</p>
<table>
<thead>
<tr>
<th><strong>File</strong></th>
<th><strong>Uncompressed size</strong></th>
<th><strong>Huffman compressed size</strong></th>
<th><strong>LZW compressed size</strong></th>
<th><strong>LZW bits</strong></th>
<th><strong>Huffman compression ratio</strong></th>
<th><strong>LZW compression ratio</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>alice_in_wonderland</td>
<td>146 kb</td>
<td>83 kb</td>
<td>67.9</td>
<td>16</td>
<td>1.759</td>
<td>2.15</td>
</tr>
<tr>
<td>jane_eyre</td>
<td>1001 kb</td>
<td>564.5 kb</td>
<td>414 kb</td>
<td>18</td>
<td>1.774</td>
<td>2.418</td>
</tr>
<tr>
<td>macbeth</td>
<td>100 kb</td>
<td>56.8 kb</td>
<td>49.7 kb</td>
<td>16</td>
<td>1.760</td>
<td>2.012</td>
</tr>
<tr>
<td>wuthering_heights</td>
<td>647 kb</td>
<td>368.4 kb</td>
<td>264 kb</td>
<td>18</td>
<td>1.756</td>
<td>2.451</td>
</tr>
</tbody>
</table>
<p>It's interesting to note that LZW performs much better than Huffman. It could be reasoned that the English language contains a lot
of repeating words and patterns, which leads to the great LZW performance.</p>
<p>Tests to compare the compression for both very unique and non-unique strings and their effects on LZW and Huffman were also conducted:</p>
<p><code>“abcdefghijklmnopqrstuvwxyz0123456789{}:&quot;!@#$%^&amp;*()”</code></p>
<table>
<thead>
<tr>
<th>File</th>
<th>File size</th>
<th>Overhead size</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Original</strong></td>
<td>50 bytes</td>
<td>No overhead</td>
</tr>
<tr>
<td><strong>LZW</strong></td>
<td>50 bytes</td>
<td>No overhead</td>
</tr>
<tr>
<td><strong>Huffman</strong></td>
<td>36 bytes</td>
<td>155 bytes overhead</td>
</tr>
</tbody>
</table>
<p>As expected, a string consisting purely of non-repeating unique characters results in no compression at all for LZW.
Ignoring the large Huffman overhead due to the rather bulky (and poor) implementation of saving the frequency table, Huffman does
perform better than LZW here.</p>
<p><code>“ababababababababababababababababababababababababab”</code></p>
<table>
<thead>
<tr>
<th>File</th>
<th>File size</th>
<th>Overhead size</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Original</strong></td>
<td>50 bytes</td>
<td>No overhead</td>
</tr>
<tr>
<td><strong>LZW</strong></td>
<td>16 bytes</td>
<td>No overhead</td>
</tr>
<tr>
<td><strong>Huffman</strong></td>
<td>7 bytes</td>
<td>12 bytes overhead</td>
</tr>
</tbody>
</table>
<p>LZW performs much better here with the repeating sequences. However, Huffman still outperforms LZW when ignoring the overhead which could
be optimized significantly.</p>
<p>Which algorithm is best is always a fight between the frequency of repeating patterns of characters and the frequency of repeating characters.
Since LZW depends on repeating patterns, it's obvious its performance improves in longer text files where there is time to build up
the dictionary and compress the repeating data.</p>
<h2 id="7-reflection">7. Reflection</h2>
<p>I learnt a lot from this assignment, of course about the topic of compression algorithms, but also a lot about working with
binary and properly reading/writing binary files. A lot of abstractions were used in this assignment that lead to (probably)
less performant code than would've been possible in a more compact implementation. However, I noticed this abstraction and properly
defining interfaces between classes helped with managing complexity. Essentially being able to close off a piece of complex
code as a &quot;black box&quot; with a simple interface and not having to worry about breaking it again.</p>
<p>An example for an improvement would be the usage of <code>std::vector&lt;bool&gt;</code> instead of binary representing strings or some form
of dynamic implementation for <code>std::bitset</code>. Both of these would represent bits as actual individual bits instead of having a full byte
overhead.</p>
<p>The code could've probably been written a lot more compact, and there are probably a lot of areas for improvement, but all-in-all
I'm satisfied with the result of a functioning(!) program that can encode and decode files reliably with two different compression
algorithms and no loss of information.</p>
<h2 id="8-references">8. References</h2>
<ul>
<li>GeeksforGeeks. <em>Huffman Coding | Greedy Algo-3</em>. &quot;https://www.geeksforgeeks.org/huffman-coding-greedy-algo-3/&quot;, accessed 24 Nov. 2023.</li>
<li>GeeksforGeeks. <em>LZW (Lempel–Ziv–Welch) Compression technique</em>. https://www.geeksforgeeks.org/lzw-lempel-ziv-welch-compression-technique/, accessed 2 Dec. 2023.</li>
<li>Pizzey Technology. <em>Huffman coding step-by-step example</em>. https://www.youtube.com/watch?v=iEm1NRyEe5c, accessed 21 Nov 2023.</li>
<li>TechRetox. <em>Lempel-Ziv-Welch Compression Algorithm - Tutorial</em>. https://www.youtube.com/watch?v=j2HSd3HCpDs, accessed 1 Dec 2023.</li>
</ul>

</body>
</html>
